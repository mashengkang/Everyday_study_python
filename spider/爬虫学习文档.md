# 爬虫学习文档

## 1.请求方式

**GET 和POST**

- GET是默认的HTTP请求方法,用于直接输入网址的方式去访问网页
- POST方法是向Web服务器提交表单数据,通常表单提交时采用
- GET把请求参数包含在url中,POST通过请求体传递参数
- GET相对POST不安全,参数直接暴漏在URL中

## 2.Requests库

安装

```
pip install requests
```

基本使用

```python
# coding:utf-8
import requests

# 定义请求的url
url = 'https://www.baidu.com'

# 发起get请求
res = requests.get(url=url)

# 获取响应结果
print(res)  # <Response [200]>
print(res.content) # b'....' 二进制文本流
print(res.text)  # 获取响应的内容
print(res.content.decode('utf-8'))  # 把二进制的文本流按照utf8的字符集转化为普通字符串
print(res.headers)  # 响应头信息
'''
{'Cache-Control': 'private, no-cache, no-store, proxy-revalidate, no-transform', 'Connection': 'keep-alive', 
'Content-Encoding': 'gzip', 'Content-Type': 'text/html', 'Date': 'Tue, 09 Nov 2021 14:54:27 GMT', 
'Last-Modified': 'Mon, 23 Jan 2017 13:24:45 GMT', 'Pragma': 'no-cache', 'Server': 'bfe/1.0.8.18', 
'Set-Cookie': 'BDORZ=27315; max-age=86400; domain=.baidu.com; path=/', 'Transfer-Encoding': 'chunked'}
'''
print(res.status_code)  # 请求状态码
print(res.url)  # 请求的url地址
print(res.request.headers)  # 请求的头信息
# {'User-Agent': 'python-requests/2.23.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
```

## 3.请求头

```python
url = 'https://www.89ip.cn/'
# 定义请求头信息
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36'
}
res = requests.get(url, headers=headers)
```

## 4.POST请求

```python
import requests

url = "https://fanyi.baidu.com/sug"
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36'
}
# post发送的数据
data = {'kw': '你好'}
res = requests.post(url=url, headers=headers, data=data)
```

## 5.cookie

http请求是无状态的请求协议,不会记住用户的状态和信息,也不清楚你在这之前访问过什么.

因为网站需要记录用户是否登录时,就需要在用户登录后创建一些信息,并且要把这些信息记录在当前用户的浏览器中,记录的内容就是cookie,用户使用当前的这个浏览器时,会主动携带这个网站设置的cookie信息

cookie会在浏览器中记录信息,并且在访问时携带这个信息.

1. 浏览器更换或删除cookie后,信息丢失
2. cookie在浏览器中记录的信息是不安全的,因为不能记录敏感信息

## 6.session

session是在服务器端进行数据的记录,并且给每个用户生成一个sessionID,并把这个sessionID设置在用户的浏览器中,也就是设置为cookie中数据

使用requests中的session

